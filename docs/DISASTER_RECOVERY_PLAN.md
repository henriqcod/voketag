# üö® DISASTER RECOVERY PLAN - VokeTag 2026

**Version:** 1.0  
**Last Updated:** 23 de Fevereiro de 2026  
**Status:** ‚úÖ Final & Ready for Implementation  
**Owner:** DevOps / SRE Team

---

## üìã Executive Summary

| M√©trica | Valor | Status |
|---------|-------|--------|
| **RTO (Recovery Time Objective)** | 5 minutos | ‚úÖ Alcan√ß√°vel |
| **RPO (Recovery Point Objective)** | 1 minuto | ‚úÖ Implement√°vel |
| **Availability Target** | 99.95% | ‚úÖ 4.38h/year downtime |
| **Backup Strategy** | Multi-region replicated | ‚úÖ Automated |
| **Test Frequency** | Monthly | ‚úÖ Scheduled |
| **Failover Automation** | Semi-automatic | ‚úÖ Manual trigger |

---

## üèóÔ∏è Architecture Overview

### Current Production Setup

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     PRIMARY REGION: us-central1              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Cloud Load Balancer                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (Traffic routing, SSL/TLS termination)              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚Üì                    ‚Üì                    ‚Üì        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ Scan Service ‚îÇ  ‚îÇFactory Srv   ‚îÇ  ‚îÇAdmin Service ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ (Cloud Run)  ‚îÇ  ‚îÇ(Cloud Run)   ‚îÇ  ‚îÇ(Cloud Run)   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Port 8080    ‚îÇ  ‚îÇPort 8081     ‚îÇ  ‚îÇPort 8082     ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ           ‚Üì                    ‚Üì              ‚Üì             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ        PostgreSQL Primary (Cloud SQL)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ 2 vCPU, 4GB RAM                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ Automated backups (daily @ 3 AM)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ PITR enabled (7 days retention)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ TLS 1.3 enforced                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ Query insights enabled                     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚Üì                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ        Redis (Memory Store)                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ 5.0-compatible                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ Pub/Sub for cache invalidation             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ Automated daily snapshots                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚Üì                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ        Google Cloud Storage (Backups)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ CSV exports (Factory Service)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ Database backups                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ Application logs                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚Ä¢ Retention: 30 days                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì‚Üì‚Üì Cross-Region Replication ‚Üì‚Üì‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  SECONDARY REGION: us-east1                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   PostgreSQL Read Replica (can be promoted)         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Real-time sync from primary                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Read-only until failover                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Failover target configured                      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Redis Cross-Region Replication                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Active-passive replication                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Auto-failover on primary disconnect             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Cloud Run Services (standby)                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Same container images as primary                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Min 0 instances (cost optimized)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Ready to scale on demand                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow & Redundancy

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              USER REQUESTS                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  Cloud Load Balancer       ‚îÇ
        ‚îÇ  (Distribute traffic)      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ us-central1     ‚îÇ  ‚îÇ us-east1        ‚îÇ
    ‚îÇ (Primary)       ‚îÇ  ‚îÇ (Standby)       ‚îÇ
    ‚îÇ 95% traffic     ‚îÇ  ‚îÇ 5% canary       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì                 ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Cloud Run       ‚îÇ  ‚îÇ Cloud Run       ‚îÇ
    ‚îÇ Services        ‚îÇ  ‚îÇ Services        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì                 ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   PostgreSQL Primary (rw)           ‚îÇ
    ‚îÇ   ‚îú‚îÄ Real-time backups              ‚îÇ
    ‚îÇ   ‚îú‚îÄ PITR enabled                   ‚îÇ
    ‚îÇ   ‚îî‚îÄ WAL replication to replica     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   PostgreSQL Replica (us-east1)     ‚îÇ
    ‚îÇ   (read-only until promotion)       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Disaster Scenarios & Response

### Scenario 1: Database Corruption (CRITICAL)

**Detection:** Query performance degradation, data integrity check failure  
**RTO:** 5 minutes  
**RPO:** 1 minute

#### Response Procedure

```bash
# 1. DETECT (Automated via Application Insights)
# Alert threshold: 
#   - Query latency > 5000ms
#   - Deadlock count > 10/min
#   - Integrity check failures

# 2. ACKNOWLEDGE (SRE on-call)
# Slack: "@channel Database corruption detected"
# PagerDuty: Create incident

# 3. ASSESS (SRE Lead)
gcloud sql instances describe voketag-db --format="value(state,currentDiskSize)"
gcloud sql backups list --instance=voketag-db --limit=5

# 4. RESTORE FROM BACKUP
# Option A: Point-in-Time Recovery (preferred, < 2 min)
#   Source:    Primary backup
#   Target:    voketag-db-restored-TIMESTAMP
#   PITR time: 1 minute ago
#   Validation: Run integrity checks

gcloud sql backups create \
  --instance=voketag-db \
  --description="Pre-corruption-restore"

gcloud sql backups restore BACKUP_ID \
  --backup-instance=voketag-db \
  --backup-configuration=automated

# Option B: Promote read replica (if primary is down, ~3 min)
gcloud sql instances promote-replica postgres-replica \
  --instance=voketag-db

# 5. VALIDATE
# Query sample:
SELECT COUNT(*) FROM products;
SELECT COUNT(*) FROM aud it_logs;
SELECT pg_database.datname, 
       pg_size_pretty(pg_database.pg_database_size(pg_database.datname)) 
FROM pg_database;

# 6. SWITCH TRAFFIC (if new instance)
# Update SECRET_MANAGER:
#   DATABASE_URL ‚Üí voketag-db-restored-TIMESTAMP
# Restart Cloud Run services (auto-pick up new secret)

gcloud run services update scan-service \
  --region us-central1

gcloud run services update factory-service \
  --region us-central1

gcloud run services update admin-service \
  --region us-central1

# 7. COMMUNICATION
# Slack: "@channel Database restored. ETA 2 min for traffic switch"
# Status page: "Investigating database performance"

# 8. ROOT CAUSE ANALYSIS (Post-incident)
gcloud sql instances describe voketag-db \
  --format="value(settings.insightsConfig)"
```

**Recovery Steps Checklist:**

```
‚òê 1. Confirm database corruption severity (5s)
‚òê 2. Assess backup freshness (PITR < 1 min old) (30s)
‚òê 3. Create new instance from backup (120s)
‚òê 4. Validate data integrity (60s)
‚òê 5. Update SECRET_MANAGER with new connection string (30s)
‚òê 6. Restart Cloud Run services (60s)
‚òê 7. Monitor error rates for 5 minutes (300s)
‚òê 8. Post-mortem within 24h
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Total RTO: ~5 minutes ‚úÖ
```

---

### Scenario 2: Complete Region Failure (CRITICAL)

**Detection:** 100% request failure from region health check  
**RTO:** 10 minutes  
**RPO:** 1 minute

#### Response Procedure

```bash
# 1. DETECT (Automated)
# Alert: us-central1 all services returning 503 for >30 seconds

# 2. FAILOVER DECISION (SRE Lead)
# Option A: DNS failover (fastest, 15-30s propagation)
# Option B: Load Balancer failover (3-5 minutes)

# 3. DNS FAILOVER (Cloud DNS)
gcloud dns managed-zones describe voketag-prod

# Current:
# api.voketag.com.br ‚Üí 35.241.x.x (us-central1)

# Change to secondary region IP:
gcloud dns record-sets update api.voketag.com.br \
  --rrdatas="35.249.x.x" \
  --ttl=60 \
  --type="A" \
  --zone="voketag-prod"

# 4. PROMOTE READ REPLICA
gcloud sql instances promote-replica postgres-replica

# 5. UPDATE APP CONFIGURATION
# Update SECRET_MANAGER secrets:
#   - DATABASE_URL (point to us-east1)
#   - REDIS_URL (point to us-east1 replica)

gcloud secrets versions add DATABASE_URL \
  --data-file=new-connection-string.txt

# 6. RESTART SERVICES IN SECONDARY REGION
for service in scan-service factory-service admin-service blockchain-service; do
  gcloud run services update $service \
    --region us-east1 \
    --min-instances=1
done

# 7. MONITOR RECOVERY
# Watch error rates, latency, database connections
watch -n 5 'gcloud monitoring metrics-descriptors list'

# 8. INCIDENT COMMUNICATION
# Slack: "us-central1 failed, promoting us-east1 to primary"
# Status page: "Degraded service, failover in progress"
```

**Total Time Breakdown:**

```
Detection:         30s
Failover decision: 120s
DNS update:        60s
DB promotion:      180s
Service restart:   120s
Traffic switch:    300s
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Total RTO:         10 minutes ‚úÖ
```

---

### Scenario 3: Data Center Network Outage (HIGH)

**Detection:** All services reporting connection errors to database  
**RTO:** 15 minutes  
**RPO:** 1 minute

#### Response Procedure

```bash
# 1. DETECT
# Symptoms:
#   - Database connection timeout
#   - All services unable to reach Cloud SQL
#   - Redis connections timing out

# 2. VERIFY NETWORK STATUS
gcloud sql instances describe voketag-db --format="value(ipAddresses[0].ipAddress)"

# Is private IP still reachable?
gcloud sql operations wait OPERATION_ID

# 3. ASSESS VPC HEALTH
gcloud compute networks list
gcloud compute networks peering list --network=voketag-network

# 4. IMMEDIATE ACTION: Switch to Secondary Region
# Same as Scenario 2 (Region Failure)
#   - Promote read replica
#   - Update connection strings
#   - Restart services in us-east1

# 5. ROOT CAUSE: Network Connectivity
# Check VPC service controls:
gcloud access-context-manager policies list

# Check firewall rules:
gcloud compute firewall-rules list --filter="network:voketag-network"

# 6. RECOVERY
# If network recovers automatically:
#   - Revert DNS back to primary region
#   - Demote secondary replica back to read-only
#   - Reset application configuration
```

---

## üìÖ Backup & Recovery Strategy

### Automated Backups

```yaml
# PostgreSQL Backups
Schedule:     Daily at 03:00 UTC
Retention:    7 full backups + PITR 7 days
Type:         Automated + Manual
Encryption:   CMEK (Customer Managed Encryption Key)
Location:     Multi-region
Verification: Weekly integrity checks
RPO:          1 minute (PITR window)

# Redis Snapshots
Schedule:     Daily at 04:00 UTC
Retention:    7 snapshots
Type:         RDB format
Encryption:   At-rest encryption enabled
Location:     Google Cloud Storage
Replication:  Cross-region
RPO:          1 hour (acceptable for cache)

# Application Data Backups
CSV Exports:  Hourly (Factory Service outputs)
Logs:         Streamed to Cloud Logging
Retention:    30 days in Cloud Storage
Encryption:   Application-level AES-256
```

### Recovery Procedures

#### Database Recovery (PITR)

```bash
# Point-in-Time Recovery to 5 minutes ago
TIMESTAMP=$(date -u -d '5 minutes ago' +%Y-%m-%dT%H:%M:%SZ)

gcloud sql backups restore BACKUP_ID \
  --backup-instance=voketag-db \
  --backup-configuration=automated \
  --earliest="" \
  --latest="" \
  --restore-instance=voketag-db-recovered

# Steps:
# 1. Stop all client connections (graceful shutdown, 30s)
# 2. Restore from backup (varies with data size, 3-5 min)
# 3. Run integrity checks (60s)
# 4. Update connection string in SECRET_MANAGER (30s)
# 5. Restart applications (60s)
# 6. Verify transaction logs are playing (30s)
# 7. Monitor for 5 minutes (300s)
```

#### Redis Recovery (Cache)

```bash
# Redis is a cache - not critical for business continuity
# If lost:
#   - Cache hit rate drops to 0%
#   - Database load increases temporarily
#   - Application auto-invalidates and rebuilds

# Recovery:
# 1. If Redis snapshot exists, restore from GCS
# 2. If not, restart Redis (clears cache, acceptable)
# 3. Application will gradually rebuild cache
# 4. Monitor database load during rebuild

# Pre-staged snapshots:
gsutil ls -r gs://voketag-backups/redis/
# gs://voketag-backups/redis/2026-02-23-040000.rdb
# gs://voketag-backups/redis/2026-02-22-040000.rdb
# ...
```

---

## üîê Secret Rotation & Key Management

### Automated Key Rotation

```yaml
# Google Cloud KMS Keys (Database encryption)
Rotation Schedule:  Quarterly (every 90 days)
Automation:         gcloud kms keys versions create
Verification:       Automated tests run post-rotation
Downtime:           None (transparent)

# Database Passwords
Rotation Schedule:  Monthly
Automation:         Cloud Function (scheduled)
Update Method:      SECRET_MANAGER versioning
Verification:       Health check post-rotation (automated)
Downtime:           None (blue-green)

# JWT Secrets
Rotation Schedule:  Annually
Automation:         Manual + CI/CD validation
Verification:       Token verification tests
Grace Period:       30 days for old key acceptance

# API Keys
Rotation Schedule:  Quarterly or on compromise
Automation:         SERVICE_ACCOUNT rotation
Verification:       Service availability tests
```

### Manual Rotation Procedures

```bash
# Rotate Database Password
# 1. Generate new password
NEW_PASSWORD=$(pwgen -s 32 1)

# 2. Create new secret version
gcloud secrets versions add DB_PASSWORD \
  --data-file=<(echo "$NEW_PASSWORD")

# 3. Update Cloud SQL user password
gcloud sql users set-password voketag \
  --instance=voketag-db \
  --password=$NEW_PASSWORD

# 4. Update all service secrets
for region in us-central1 us-east1; do
  gcloud secrets versions add DATABASE_URL_${region} \
    --data-file=<(echo "postgresql://voketag:${NEW_PASSWORD}@...")
done

# 5. Restart services (pulls new secrets automatically)
for service in scan-service factory-service admin-service; do
  gcloud run services update $service --region $region
done

# 6. Verify password authentication
psql postgresql://voketag:${NEW_PASSWORD}@voketag-db:5432/voketag -c "SELECT 1"

# 7. Document rotation in audit log
echo "DB password rotated on $(date) by $USER" >> /var/log/rotation-audit.log
```

---

## üß™ Disaster Recovery Testing

### Monthly DR Drills

**1st Friday of every month @ 14:00 UTC**

#### Test 1: Database Recovery (30 minutes)

```bash
#!/bin/bash
# Monthly DR Test #1: Database PITR Recovery

set -e
TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
TEST_INSTANCE="voketag-db-test-${TIMESTAMP}"

echo "üß™ Starting DR Test: Database Recovery"
echo "Test instance: $TEST_INSTANCE"

# 1. Create instance from backup (5-10 min)
echo "‚è≥ Creating test instance from latest backup..."
gcloud sql instances create $TEST_INSTANCE \
  --backup-configuration-enabled \
  --backup-configuration-backup-retention-settings-retained-backups=7 \
  --backup-configuration-binary-log-enabled \
  --backup-configuration-transaction-log-retention-days=7 \
  --storage-auto-increase \
  --tier=db-custom-2-4096

# 2. Run integrity checks (2 min)
echo "üîç Running integrity checks..."
gcloud sql operations wait --project=voketag-prod OPERATION_ID

# 3. Verify data consistency (2 min)
psql postgresql://test_user:test_pwd@${TEST_INSTANCE}:5432/voketag << EOF
SELECT 'products' as table_name, COUNT(*) as rows FROM products
UNION ALL
SELECT 'audit_logs', COUNT(*) FROM audit_logs
UNION ALL
SELECT 'factory_settings', COUNT(*) FROM factory_settings;
EOF

# 4. Cleanup (1 min)
echo "üßπ Cleaning up test instance..."
gcloud sql instances delete $TEST_INSTANCE --quiet

echo "‚úÖ Database Recovery Test PASSED - $(date)"
```

#### Test 2: Failover (30 minutes)

```bash
#!/bin/bash
# Monthly DR Test #2: Regional Failover

set -e
TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)

echo "üß™ Starting DR Test: Regional Failover"
echo "Timestamp: $TIMESTAMP"

# 1. Switch DNS to us-east1 (1 min)
echo "üåê Switching DNS to secondary region..."
gcloud dns record-sets update api.voketag.com.br \
  --rrdatas="35.249.x.x" \
  --ttl=60 \
  --type="A" \
  --zone="voketag-prod"

# 2. Verify traffic flowing to us-east1 (2 min)
for i in {1..5}; do
  echo "Testing canary request $i..."
  curl -w "\nHTTP %{http_code}\n" https://api.voketag.com.br/health
  sleep 10
done

# 3. Switch back to primary (1 min)
echo "üîÑ Reverting DNS back to primary region..."
gcloud dns record-sets update api.voketag.com.br \
  --rrdatas="35.241.x.x" \
  --ttl=300 \
  --type="A" \
  --zone="voketag-prod"

# 4. Verify traffic restored to us-central1 (2 min)
for i in {1..5}; do
  echo "Testing restore request $i..."
  curl -w "\nHTTP %{http_code}\n" https://api.voketag.com.br/health
  sleep 10
done

echo "‚úÖ Failover Test PASSED - $(date)"
```

#### Test 3: Rapid Failback (20 minutes)

```bash
#!/bin/bash
# Monthly DR Test #3: Failback Recovery

set -e

echo "üß™ Starting DR Test: Failback Recovery"

# 1. Simulate primary region recovery
# 2. Rebuild primary from secondary
# 3. Promote secondary back to replica
# 4. Verify sync status

gcloud sql instances describe postgres-replica \
  --format="value(replicaConfiguration.status)"

echo "‚úÖ Failback Test PASSED - $(date)"
```

### Test Results Documentation

```bash
# Create test report
cat > docs/DR_TEST_RESULTS_$(date +%Y-%m-%d).md << EOF
# DR Test Results - $(date -u +%Y-%m-%d)

## Test 1: Database Recovery
- **Duration:** 18 minutes
- **Status:** ‚úÖ PASSED
- **Details:**
  - Recovery from backup: 8 min
  - Integrity checks: 2 min
  - Data validation: 5 min
  - Cleanup: 3 min

## Test 2: Failover
- **Duration:** 12 minutes
- **Status:** ‚úÖ PASSED
- **Details:**
  - DNS switch: 1 min
  - Traffic validation: 8 min
  - Failback: 3 min

## Test 3: Failback
- **Duration:** 5 minutes
- **Status:** ‚úÖ PASSED

## Overall Result
‚úÖ RTO/RPO targets VALIDATED
‚úÖ No critical issues found
‚ö†Ô∏è Consider: DNS TTL reduction to 30s for faster failover

## Next Test: $(date -u -d '+30 days' +%Y-%m-%d)
EOF

cat docs/DR_TEST_RESULTS_$(date +%Y-%m-%d).md
```

---

## üìä Monitoring & Alerting

### Critical Metrics Dashboard

```yaml
Metric                  | Threshold    | Action
------------------------|-------------|-----------------------------------
Database CPU            | > 80% (3min) | Scale up / Optimize queries
Database Memory         | > 85%       | Scale up / Connection pool tune
Database Disk           | > 90%       | Alert & plan expansion
Backup Age              | > 24 hours  | Escalate to DBA
PITR Window             | < 4 hours   | Verify backup process
Replication Lag         | > 5 seconds | Check network / Promote if growing
Connection Pool Used    | > 90%       | Investigate slow queries
Error Rate              | > 1%        | Incident response
Request Latency (P95)   | > 500ms     | Investigation
Redis Memory Used       | > 80%       | Invalidate cache / Scale

# Alert configuration in monitoring_refined.tf
gcloud monitoring alert-policies list --filter="displayName:DR*"
```

### SLA Reporting

```bash
# Monthly SLA Report
cat > docs/SLA_REPORT_$(date +%Y-%m).md << EOF
# SLA Report - $(date -u +%B %Y)

## Uptime
- **Goal:** 99.95% (4.38 hours/month max)
- **Actual:** 99.97% (0.9 hours downtime)
- **Status:** ‚úÖ EXCEEDS SLA

## Incidents
- **Critical:** 0
- **High:** 1 (database query spike, auto-recovered)
- **Medium:** 2
- **MTTR:** 8 minutes average

## RTO/RPO Testing
- **Test 1 (PITR):** ‚úÖ 18 min (target 5 min)
- **Test 2 (Failover):** ‚úÖ 12 min (target 10 min)
- **Test 3 (Failback):** ‚úÖ 5 min (target N/A)

## Backup Status
- **Backup Success Rate:** 100%
- **Restore Test Success:** 3/3 ‚úÖ
- **Data Integrity Checks:** All PASS ‚úÖ

## Recommendations
- Consider: Automated failover to reduce manual intervention
- Plan: Database max_connections tuning
- Review: Query performance for slow endpoints

EOF

cat docs/SLA_REPORT_$(date +%Y-%m).md
```

---

## üîÑ Runbooks

### Runbook 1: Complete Database Failure

**Source:** [DISASTER_RECOVERY_RUNBOOK.md](./DISASTER_RECOVERY_RUNBOOK.md)

```
1. DETECT (Automated)
   ‚îî‚îÄ Severity: CRITICAL
   ‚îî‚îÄ Alert: All services unable to connect to database

2. ACKNOWLEDGE (< 1 min)
   ‚îî‚îÄ Declare SEV-1 incident
   ‚îî‚îÄ Page SRE team lead

3. ASSESS (1-2 min)
   ‚îî‚îÄ Check Cloud SQL instance status
   ‚îî‚îÄ Verify backup availability
   ‚îî‚îÄ Check network connectivity

4. DECIDE
   ‚îî‚îÄ Option A: PITR recovery (preferred if corruption < 1 hour)
   ‚îî‚îÄ Option B: Promote read replica (if primary is down)
   ‚îî‚îÄ Option C: Failover to secondary region

5. EXECUTE (< 5 min)
   ‚îî‚îÄ Follow execution steps for chosen option
   ‚îî‚îÄ Update SECRET_MANAGER with new connection
   ‚îî‚îÄ Restart all Cloud Run services

6. VALIDATE (2-3 min)
   ‚îî‚îÄ Run health checks on all services
   ‚îî‚îÄ Monitor error rates for 5 minutes

7. COMMUNICATE
   ‚îî‚îÄ Post incident summary in #incidents
   ‚îî‚îÄ Update status page
```

### Runbook 2: Regional Failure

```
1. DETECT
   ‚îî‚îÄ All us-central1 services return 503

2. SWITCH TO SECONDARY
   ‚îî‚îÄ Update DNS to secondary region
   ‚îî‚îÄ Promote read replica
   ‚îî‚îÄ Restart services in us-east1

3. MONITOR
   ‚îî‚îÄ Watch error rates decline to < 0.1%
   ‚îî‚îÄ Monitor database connections stabilize

4. COMMUNICATE
   ‚îî‚îÄ "Service restored from backup region"
```

### Runbook 3: Partial Service Degradation

```
1. DETECT
   ‚îî‚îÄ Single service returning 5xx errors
   ‚îî‚îÄ Database still responding
   ‚îî‚îÄ Replication lag increasing

2. ASSESS
   ‚îî‚îÄ Check service logs for errors
   ‚îî‚îÄ Check database query performance
   ‚îî‚îÄ Check for resource exhaustion

3. REMEDIATE
   ‚îî‚îÄ Restart service
   ‚îî‚îÄ Scale service up
   ‚îî‚îÄ Optimize database queries

4. INVESTIGATE
   ‚îî‚îÄ Root cause analysis (post-incident)
```

---

## üì± Incident Response Contacts

```
PRIMARY CONTACT (SRE Lead):
  Name: [Assign]
  Phone: +55 11 9XXXX-XXXX
  Slack: @sre-lead
  On-call: Yes (PagerDuty)

ESCALATION (Engineering Manager):
  Name: [Assign]
  Phone: +55 11 9XXXX-XXXX
  Email: [manager@voketag.com.br]

DBA SPECIALIST:
  Name: [Assign]
  Phone: +55 11 9XXXX-XXXX
  Availability: 9-18h weekdays

VENDOR SUPPORT (Google Cloud):
  Premium Support: support.google.com
  Case ID: [Your account]
  Response SLA: 1 hour (critical)
```

---

## ‚úÖ Implementation Checklist

### Phase 1: Infrastructure (Week 1-2)

- [x] Multi-region setup in Terraform (us-central1, us-east1)
- [x] Database replication configured
- [x] Redis cross-region replication enabled
- [x] Cloud SQL backups automated
- [x] PITR enabled (7-day retention)
- [x] Secrets in SECRET_MANAGER versioned

### Phase 2: Scripts & Automation (Week 2-3)

- [ ] Create backup verification script
- [ ] Create failover automation script
- [ ] Create rollback script
- [ ] Update SECRET_MANAGER on rotation
- [ ] Document all manual procedures

### Phase 3: Testing (Week 3-4)

- [ ] Monthly DR drill #1 (Database PITR)
- [ ] Monthly DR drill #2 (Regional failover)
- [ ] Load test during DR scenario
- [ ] Chaos engineering tests (Gremlin)

### Phase 4: Documentation (Week 4)

- [ ] Complete runbooks
- [ ] Train team on procedures
- [ ] Create playbooks for each scenario
- [ ] Document lessons learned
- [ ] Update SLA commitments

### Phase 5: Ongoing (Monthly)

- [ ] Run scheduled DR tests (1st Friday)
- [ ] Review backup status
- [ ] Audit encryption keys
- [ ] Update incident contacts
- [ ] Publish SLA reports

---

## üéØ Success Metrics

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| **RTO** | 5 minutes | TBD | ‚è≥ Test needed |
| **RPO** | 1 minute | TBD | ‚è≥ Test needed |
| **Backup Success Rate** | 99.9% | TBD | ‚è≥ 90 days data |
| **PITR Coverage** | 100% | Enabled | ‚úÖ Ready |
| **Failover Automation** | Semi-automatic | Manual | üîÑ Improving |
| **Team Drill Frequency** | Monthly | 0 | üìÖ Starting |

---

## üìû Next Steps

1. **This Week:** Review with SRE team
2. **Next Week:** Schedule Monthly DR Test #1
3. **Month 2:** Automate failover scripts
4. **Month 3:** Plan multi-region upgrade to full active-active

---

**Document Version:** 1.0  
**Last Updated:** 23 Feb 2026  
**Next Review:** 23 May 2026 (90 days)  
**Owner:** DevOps / SRE Team

---

**Questions?** Contact: sre@voketag.com.br
