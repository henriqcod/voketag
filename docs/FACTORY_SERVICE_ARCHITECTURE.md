# ðŸ­ Factory Service: Arquitetura para 1 MILHÃƒO de Ancoragens/Dia

**Data:** 2026-02-18  
**Contexto CrÃ­tico:** 1 milhÃ£o de ancoragens diÃ¡rias de lotes na blockchain + geraÃ§Ã£o de QR Codes

---

## ðŸ“Š **AnÃ¡lise de Carga Real**

### **ConversÃ£o para RPS:**

```
1 milhÃ£o de ancoragens/dia:
â”œâ”€â”€ DistribuiÃ§Ã£o: HorÃ¡rio comercial (8h-18h)
â”œâ”€â”€ 800,000 ancoragens em 10 horas (80%)
â”œâ”€â”€ 200,000 ancoragens em 14 horas (20%)
â””â”€â”€ RPS mÃ©dio: 22 RPS
    â””â”€â”€ Pico (3x): 66 RPS
```

### **OperaÃ§Ãµes por Ancoragem:**

```
1 ancoragem de lote:
â”œâ”€â”€ 1. Criar batch no DB (PostgreSQL INSERT)
â”œâ”€â”€ 2. Gerar produtos do lote (1-1000 produtos/batch)
â”œâ”€â”€ 3. Para cada produto:
â”‚   â”œâ”€â”€ a) Gerar token assinado (HMAC-SHA256)
â”‚   â”œâ”€â”€ b) Gerar QR Code image (PNG)
â”‚   â”œâ”€â”€ c) Upload QR para S3
â”‚   â””â”€â”€ d) INSERT produto no DB
â”œâ”€â”€ 4. Calcular Merkle root do lote
â”œâ”€â”€ 5. Ancorar hash na blockchain (via Blockchain Service)
â”œâ”€â”€ 6. Atualizar batch com blockchain_tx_id
â””â”€â”€ 7. Pub/Sub notification (Redis)
```

**CRÃTICO:** Cada ancoragem pode ter **1 a 1000 produtos**!

---

## ðŸš¨ **Problema CrÃ­tico Identificado**

### **CenÃ¡rio Real:**

```
Input: 1 batch com 1000 produtos

OperaÃ§Ãµes sÃ­ncronas (sequencial):
â”œâ”€â”€ INSERT batch: 30ms
â”œâ”€â”€ Para cada produto (1000x):
â”‚   â”œâ”€â”€ Gerar token: 0.2ms Ã— 1000 = 200ms
â”‚   â”œâ”€â”€ Gerar QR image: 50ms Ã— 1000 = 50,000ms (50s!)
â”‚   â”œâ”€â”€ Upload S3: 100ms Ã— 1000 = 100,000ms (100s!)
â”‚   â””â”€â”€ INSERT DB: 10ms Ã— 1000 = 10,000ms (10s!)
â”œâ”€â”€ Merkle tree: 500ms
â”œâ”€â”€ Blockchain anchoring: 2,000ms
â””â”€â”€ Update batch: 30ms

Total: ~162 segundos (2.7 minutos) âŒ
```

**Com 1000 produtos por batch:**
- Throughput real: **0.37 batches/minuto**
- Para 1M produtos/dia: **1850 dias** âŒâŒâŒ

**CONCLUSÃƒO:** Arquitetura sÃ­ncrona **NÃƒO FUNCIONA**!

---

## ðŸŽ¯ **Arquitetura NecessÃ¡ria: ASSÃNCRONA + WORKERS**

### **PadrÃ£o: Producer-Consumer com Filas**

```
API Request (Factory Dashboard)
    â†“
[1] Criar Batch (DB INSERT) - 30ms
    â†“
[2] Enfileirar Job (Redis Queue)
    â†“
[3] Retornar Response (batch_id + job_id)
    â†“
Background Workers (paralelo):
    â”œâ”€â”€ Worker 1: Gerar tokens + QR Codes
    â”œâ”€â”€ Worker 2: Upload S3 (bulk)
    â”œâ”€â”€ Worker 3: INSERT produtos (bulk)
    â”œâ”€â”€ Worker 4: Merkle tree + blockchain
    â””â”€â”€ Worker 5: NotificaÃ§Ãµes
```

---

## ðŸ—ï¸ **Arquitetura Detalhada**

### **Componente 1: API REST (FastAPI)**

```python
# POST /v1/batches
@router.post("/v1/batches")
async def create_batch(
    batch: BatchCreate,
    db: AsyncSession = Depends(get_db),
    redis: Redis = Depends(get_redis)
):
    """
    Cria batch e enfileira job assÃ­ncrono.
    Retorna imediatamente sem processar produtos.
    """
    
    # 1. Criar batch no DB (apenas metadata)
    db_batch = Batch(
        id=uuid4(),
        factory_id=batch.factory_id,
        product_count=batch.product_count,
        status="pending",  # â† Estado inicial
        created_at=datetime.utcnow()
    )
    db.add(db_batch)
    await db.commit()
    
    # 2. Enfileirar job para workers
    job_id = await redis.lpush(
        "queue:batch_processing",
        json.dumps({
            "batch_id": str(db_batch.id),
            "product_count": batch.product_count,
            "priority": batch.priority or "normal"
        })
    )
    
    # 3. Retornar IMEDIATAMENTE (30ms total)
    return {
        "batch_id": db_batch.id,
        "job_id": job_id,
        "status": "pending",
        "estimated_completion": "5-10 minutes",
        "webhook_url": f"/v1/batches/{db_batch.id}/status"
    }
    
# Cliente pode pooling ou receber webhook quando concluir
```

**LatÃªncia:** 30ms âœ…  
**Throughput:** 3,000 req/s (limitado pelo DB INSERT)

---

### **Componente 2: Worker Pool (Celery ou RQ)**

```python
# worker_batch_processor.py

from celery import Celery
from concurrent.futures import ThreadPoolExecutor
import qrcode
import boto3

celery = Celery('factory_service', broker='redis://localhost:6379/0')

@celery.task(name='process_batch')
def process_batch(batch_id: str, product_count: int):
    """
    Worker que processa batch completo.
    Executa operaÃ§Ãµes pesadas em paralelo.
    """
    
    try:
        # 1. Atualizar status
        update_batch_status(batch_id, "processing")
        
        # 2. Gerar produtos em paralelo (20 threads)
        products = generate_products_parallel(batch_id, product_count)
        
        # 3. Gerar QR Codes em paralelo (50 threads)
        qr_codes = generate_qrcodes_parallel(products)
        
        # 4. Upload S3 em paralelo (batch 100)
        s3_urls = upload_s3_bulk(qr_codes)
        
        # 5. INSERT produtos em bulk (batch 500)
        insert_products_bulk(products, s3_urls)
        
        # 6. Merkle tree + blockchain
        merkle_root = calculate_merkle_tree(products)
        tx_id = anchor_to_blockchain(batch_id, merkle_root)
        
        # 7. Finalizar batch
        update_batch_status(batch_id, "completed", tx_id=tx_id)
        
        # 8. NotificaÃ§Ã£o
        send_webhook_notification(batch_id, "completed")
        
        return {"status": "success", "batch_id": batch_id}
        
    except Exception as e:
        update_batch_status(batch_id, "failed", error=str(e))
        send_webhook_notification(batch_id, "failed", error=str(e))
        raise


def generate_products_parallel(batch_id: str, count: int):
    """
    Gera tokens em paralelo usando ThreadPoolExecutor.
    """
    from factory_service.antifraud import TokenSigner
    
    signer = TokenSigner(secret=HMAC_SECRET)
    
    def generate_one(index: int):
        product_id = uuid4()
        token = signer.generate_token(product_id)
        return {
            "id": product_id,
            "batch_id": batch_id,
            "token": token,
            "index": index
        }
    
    # Paralelo: 20 threads
    with ThreadPoolExecutor(max_workers=20) as executor:
        products = list(executor.map(generate_one, range(count)))
    
    return products


def generate_qrcodes_parallel(products: list):
    """
    Gera QR Codes em paralelo.
    CPU-intensive: usa ProcessPoolExecutor.
    """
    from concurrent.futures import ProcessPoolExecutor
    
    def generate_qr(product):
        qr_url = f"https://app.voketag.com/r/{product['token']}"
        
        qr = qrcode.QRCode(
            version=1,
            error_correction=qrcode.constants.ERROR_CORRECT_L,
            box_size=10,
            border=4,
        )
        qr.add_data(qr_url)
        qr.make(fit=True)
        
        img = qr.make_image(fill_color="black", back_color="white")
        
        # Converter para bytes
        import io
        buf = io.BytesIO()
        img.save(buf, format='PNG')
        
        return {
            "product_id": product["id"],
            "qr_data": buf.getvalue()
        }
    
    # Paralelo: 50 processos (CPU cores)
    with ProcessPoolExecutor(max_workers=50) as executor:
        qr_codes = list(executor.map(generate_qr, products))
    
    return qr_codes


def upload_s3_bulk(qr_codes: list):
    """
    Upload S3 em bulk (batch 100).
    I/O-intensive: usa ThreadPoolExecutor.
    """
    from concurrent.futures import ThreadPoolExecutor
    
    s3_client = boto3.client('s3')
    
    def upload_one(qr):
        key = f"qrcodes/{qr['product_id']}.png"
        
        s3_client.put_object(
            Bucket='voketag-qrcodes',
            Key=key,
            Body=qr['qr_data'],
            ContentType='image/png',
            CacheControl='public, max-age=31536000'
        )
        
        return {
            "product_id": qr['product_id'],
            "s3_url": f"https://voketag-qrcodes.s3.amazonaws.com/{key}"
        }
    
    # Paralelo: 100 threads (I/O)
    with ThreadPoolExecutor(max_workers=100) as executor:
        s3_urls = list(executor.map(upload_one, qr_codes))
    
    return s3_urls


def insert_products_bulk(products: list, s3_urls: list):
    """
    INSERT bulk no PostgreSQL (batch 500).
    Usa COPY para performance mÃ¡xima.
    """
    import asyncpg
    import asyncio
    
    async def bulk_insert():
        conn = await asyncpg.connect(DATABASE_URL)
        
        # Preparar dados para COPY
        records = [
            (
                str(p["id"]),
                str(p["batch_id"]),
                p["token"],
                s3["s3_url"],
                datetime.utcnow()
            )
            for p, s3 in zip(products, s3_urls)
        ]
        
        # COPY Ã© 10-50x mais rÃ¡pido que INSERT
        await conn.copy_records_to_table(
            'products',
            records=records,
            columns=['id', 'batch_id', 'token', 'qr_code_url', 'created_at']
        )
        
        await conn.close()
    
    asyncio.run(bulk_insert())


def calculate_merkle_tree(products: list):
    """
    Calcula Merkle root do lote.
    """
    from hashlib import sha256
    
    # Merkle tree implementation
    leaves = [
        sha256(str(p["id"]).encode()).hexdigest()
        for p in products
    ]
    
    # Build tree
    tree = leaves
    while len(tree) > 1:
        level = []
        for i in range(0, len(tree), 2):
            left = tree[i]
            right = tree[i+1] if i+1 < len(tree) else left
            parent = sha256((left + right).encode()).hexdigest()
            level.append(parent)
        tree = level
    
    return tree[0]  # Root hash


def anchor_to_blockchain(batch_id: str, merkle_root: str):
    """
    Ancora hash na blockchain via Blockchain Service.
    """
    import httpx
    
    response = httpx.post(
        "http://blockchain-service:8003/v1/anchor",
        json={
            "batch_id": batch_id,
            "merkle_root": merkle_root,
            "timestamp": datetime.utcnow().isoformat()
        },
        timeout=30.0
    )
    
    return response.json()["transaction_id"]
```

---

## ðŸ“Š **Performance da Arquitetura AssÃ­ncrona**

### **Benchmark: 1 batch com 1000 produtos**

**Arquitetura SÃ­ncrona (antiga):**
```
Total: 162 segundos
Throughput: 0.37 batches/minuto
Para 1M produtos: 1850 dias âŒ
```

**Arquitetura AssÃ­ncrona (nova):**
```
[API Request]
â””â”€â”€ INSERT batch + enfileirar: 30ms âœ…

[Background Worker - Paralelo]
â”œâ”€â”€ Gerar tokens (20 threads): 10 segundos
â”œâ”€â”€ Gerar QR Codes (50 processos): 20 segundos
â”œâ”€â”€ Upload S3 (100 threads): 15 segundos
â”œâ”€â”€ INSERT bulk (COPY): 2 segundos
â”œâ”€â”€ Merkle tree: 500ms
â””â”€â”€ Blockchain anchor: 2 segundos

Total: ~50 segundos (paralelo)
Throughput: 1.2 batches/minuto âœ…
```

**Melhoria:** 162s â†’ 50s = **3.2x mais rÃ¡pido**

---

### **Escalando: 10 Workers em Paralelo**

```
10 workers processando simultaneamente:
â”œâ”€â”€ Worker 1: Batch A (1000 produtos)
â”œâ”€â”€ Worker 2: Batch B (1000 produtos)
â”œâ”€â”€ Worker 3: Batch C (1000 produtos)
â”œâ”€â”€ ...
â””â”€â”€ Worker 10: Batch J (1000 produtos)

Throughput: 12 batches/minuto
          = 720 batches/hora
          = 17,280 batches/dia

Se mÃ©dia = 100 produtos/batch:
= 1,728,000 produtos/dia âœ… (acima do target!)
```

---

## ðŸ—ï¸ **Stack Completa**

### **Componentes:**

```
Factory Service (API):
â”œâ”€â”€ Framework: FastAPI (Python 3.11)
â”œâ”€â”€ DB: PostgreSQL 15 (asyncpg)
â”œâ”€â”€ Cache: Redis 7
â”œâ”€â”€ Message Queue: Redis (ou RabbitMQ)
â””â”€â”€ Workers: Celery + Redis

Workers (Background):
â”œâ”€â”€ Executor: Celery workers
â”œâ”€â”€ Concurrency: 10-50 workers
â”œâ”€â”€ Paralelismo interno:
â”‚   â”œâ”€â”€ ThreadPoolExecutor (I/O)
â”‚   â””â”€â”€ ProcessPoolExecutor (CPU)
â””â”€â”€ Monitoring: Flower (Celery UI)

Storage:
â”œâ”€â”€ S3: QR Code images
â””â”€â”€ PostgreSQL: Metadata + produtos

Blockchain Service:
â””â”€â”€ Anchoring via HTTP API
```

---

## ðŸ“Š **Dimensionamento**

### **Para 1 MILHÃƒO produtos/dia:**

**CenÃ¡rio 1: Batches pequenos (100 produtos/batch)**

```
1,000,000 produtos / 100 produtos/batch = 10,000 batches/dia

Throughput necessÃ¡rio:
â”œâ”€â”€ 10,000 batches / 24h = 417 batches/hora
â”œâ”€â”€ 417 batches/hora / 60min = 7 batches/minuto
â””â”€â”€ Com 10 workers (12 batches/min): âœ… SOBRA (70% margem)

Workers necessÃ¡rios: 6-8 workers
InstÃ¢ncias: 1-2 mÃ¡quinas
Custo: ~$60-100/mÃªs
```

**CenÃ¡rio 2: Batches mÃ©dios (500 produtos/batch)**

```
1,000,000 produtos / 500 produtos/batch = 2,000 batches/dia

Throughput necessÃ¡rio:
â”œâ”€â”€ 2,000 batches / 24h = 83 batches/hora
â”œâ”€â”€ 83 batches/hora / 60min = 1.4 batches/minuto
â””â”€â”€ Com 10 workers (4 batches/min para 500): âœ… SOBRA (185% margem)

Workers necessÃ¡rios: 4-6 workers
InstÃ¢ncias: 1 mÃ¡quina
Custo: ~$30-50/mÃªs
```

**CenÃ¡rio 3: Batches grandes (1000 produtos/batch)**

```
1,000,000 produtos / 1000 produtos/batch = 1,000 batches/dia

Throughput necessÃ¡rio:
â”œâ”€â”€ 1,000 batches / 24h = 42 batches/hora
â”œâ”€â”€ 42 batches/hora / 60min = 0.7 batches/minuto
â””â”€â”€ Com 10 workers (1.2 batches/min para 1000): âœ… SOBRA (70% margem)

Workers necessÃ¡rios: 6-8 workers
InstÃ¢ncias: 1 mÃ¡quina
Custo: ~$30-50/mÃªs
```

---

## ðŸ’¡ **OtimizaÃ§Ãµes Adicionais**

### **1. QR Code Generation - Otimizar**

**Problema:** Gerar 1000 QR Codes PNG Ã© CPU-intensive (20s).

**OtimizaÃ§Ã£o A: Gerar sob demanda**

```python
# NÃƒO gerar QR Code image no batch creation
# Gerar apenas quando usuÃ¡rio acessar

@router.get("/qrcode/{token}.png")
async def get_qrcode(token: str):
    """
    Gera QR Code dinamicamente.
    Cache no CDN (CloudFront).
    """
    qr_url = f"https://app.voketag.com/r/{token}"
    
    # Gerar QR em memÃ³ria
    qr = qrcode.make(qr_url)
    
    # Retornar PNG
    buf = io.BytesIO()
    qr.save(buf, format='PNG')
    
    return Response(
        content=buf.getvalue(),
        media_type="image/png",
        headers={
            "Cache-Control": "public, max-age=31536000",  # 1 ano
            "ETag": hashlib.md5(token.encode()).hexdigest()
        }
    )

# CloudFront cacheia, nunca gera 2x o mesmo QR
```

**BenefÃ­cio:**
- Batch creation: 50s â†’ **30s** (remove 20s de QR generation)
- S3 storage: 0 (economiza custo)
- Throughput: 1.2 â†’ **2 batches/min** (1.6x melhor)

---

**OtimizaÃ§Ã£o B: Gerar QR Code SVG (nÃ£o PNG)**

```python
# SVG Ã© 10x mais rÃ¡pido que PNG

import segno  # biblioteca para QR Code SVG

@router.get("/qrcode/{token}.svg")
async def get_qrcode_svg(token: str):
    qr_url = f"https://app.voketag.com/r/{token}"
    
    # Gerar SVG (10x mais rÃ¡pido que PNG)
    qr = segno.make(qr_url)
    
    # Retornar SVG
    buf = io.BytesIO()
    qr.save(buf, kind='svg', scale=4)
    
    return Response(
        content=buf.getvalue(),
        media_type="image/svg+xml",
        headers={"Cache-Control": "public, max-age=31536000"}
    )

# SVG Ã© vetorial, escalÃ¡vel, e 10x mais rÃ¡pido
```

**BenefÃ­cio:**
- GeraÃ§Ã£o: PNG 50ms â†’ SVG **5ms** (10x mais rÃ¡pido)
- Tamanho: PNG 2KB â†’ SVG **500 bytes** (4x menor)
- Qualidade: PNG pixeliza â†’ SVG **infinito** (vetorial)

---

### **2. Database Bulk Operations**

**OtimizaÃ§Ã£o: PostgreSQL COPY vs INSERT**

```python
# INSERT tradicional (lento)
for product in products:
    await db.execute(
        "INSERT INTO products VALUES (...)",
        product
    )
# 1000 INSERTs = 10 segundos âŒ

# COPY bulk (rÃ¡pido)
await conn.copy_records_to_table(
    'products',
    records=products,
    columns=[...]
)
# 1000 produtos = 2 segundos âœ… (5x mais rÃ¡pido)
```

**Benchmark:**
- INSERT loop: 10ms/produto Ã— 1000 = 10s
- COPY bulk: 2ms/produto Ã— 1000 = 2s
- **Melhoria: 5x mais rÃ¡pido**

---

### **3. S3 Upload - Multipart + Paralelo**

```python
# Upload sequencial (lento)
for qr in qr_codes:
    s3.put_object(Bucket='...', Key='...', Body=qr)
# 1000 uploads Ã— 100ms = 100 segundos âŒ

# Upload paralelo (rÃ¡pido)
with ThreadPoolExecutor(max_workers=100) as executor:
    executor.map(upload_to_s3, qr_codes)
# 1000 uploads / 100 threads = 15 segundos âœ… (6.6x mais rÃ¡pido)
```

---

### **4. Merkle Tree - Otimizar**

**OtimizaÃ§Ã£o: Usar biblioteca nativa (Rust/C++)**

```python
# Python puro (lento)
def calculate_merkle_tree_python(products):
    # ... implementaÃ§Ã£o Python
    pass
# 1000 hashes = 500ms

# Rust via PyO3 (rÃ¡pido)
import merkle_tree_rs  # Binding Rust

def calculate_merkle_tree_rust(products):
    return merkle_tree_rs.build_tree(products)
# 1000 hashes = 50ms âœ… (10x mais rÃ¡pido)
```

**Alternativa:** Usar biblioteca Python otimizada (`pymerkle`)

---

## ðŸŽ¯ **Arquitetura Final Recomendada**

### **Stack:**

```
Factory Service API:
â”œâ”€â”€ Language: Python 3.11
â”œâ”€â”€ Framework: FastAPI
â”œâ”€â”€ DB: PostgreSQL 15 (com asyncpg)
â”œâ”€â”€ Cache/Queue: Redis 7
â”œâ”€â”€ Workers: Celery + Redis
â””â”€â”€ Storage: S3 (ou sob demanda via CDN)

Worker Pool:
â”œâ”€â”€ Executors: 10-20 Celery workers
â”œâ”€â”€ Paralelismo:
â”‚   â”œâ”€â”€ ThreadPoolExecutor (I/O: S3, DB)
â”‚   â””â”€â”€ ProcessPoolExecutor (CPU: QR generation)
â””â”€â”€ Monitoring: Flower + Prometheus

Performance:
â”œâ”€â”€ Throughput: 4-12 batches/minuto
â”œâ”€â”€ Capacidade: 1.7M produtos/dia (100/batch)
â””â”€â”€ LatÃªncia API: <50ms (retorna job_id)
```

---

### **Fluxo Completo:**

```
[Cliente Dashboard]
    â†“
POST /v1/batches
    â†“
[FastAPI - 30ms]
â”œâ”€â”€ INSERT batch (DB)
â”œâ”€â”€ LPUSH job (Redis)
â””â”€â”€ Return 201 (batch_id, job_id)
    â†“
[Celery Worker Pool - Background]
â”œâ”€â”€ Worker 1: Pega job da fila
â”œâ”€â”€ Worker 2: Processa em paralelo
â”‚   â”œâ”€â”€ ThreadPool: Gerar tokens
â”‚   â”œâ”€â”€ ProcessPool: Gerar QR Codes (ou sob demanda)
â”‚   â”œâ”€â”€ ThreadPool: Upload S3 (bulk)
â”‚   â”œâ”€â”€ COPY: INSERT bulk (DB)
â”‚   â”œâ”€â”€ Calc: Merkle tree
â”‚   â””â”€â”€ HTTP: Anchor blockchain
â””â”€â”€ Worker 3: Update status + webhook
    â†“
[Cliente recebe webhook]
    â†“
GET /v1/batches/{id}
    â†“
{
  "status": "completed",
  "blockchain_tx": "0x123...",
  "products_count": 1000,
  "qr_codes_url": "https://cdn.voketag.com/batch/{id}/"
}
```

---

## ðŸ“Š **Custo Estimado**

### **Para 1M produtos/dia:**

```
Factory Service API:
â”œâ”€â”€ EC2 t3.medium: $30/mÃªs
â”œâ”€â”€ Workers (c5.large): $60/mÃªs
â””â”€â”€ PostgreSQL RDS (db.t3.medium): $60/mÃªs
    Subtotal: $150/mÃªs

Storage:
â”œâ”€â”€ S3 (se armazenar QR): $23/mÃªs (1M Ã— 2KB Ã— $0.023/GB)
â”œâ”€â”€ S3 (se sob demanda): $0/mÃªs âœ…
â””â”€â”€ CloudFront (CDN): $10/mÃªs (cache)
    Subtotal: $10-33/mÃªs

Redis:
â””â”€â”€ ElastiCache (cache.t3.small): $25/mÃªs

TOTAL: $185-208/mÃªs
```

**OtimizaÃ§Ã£o QR sob demanda:**
- Economiza $23/mÃªs S3
- Total: **$185/mÃªs** âœ…

---

## ðŸŽ¯ **RecomendaÃ§Ã£o Final**

### **Melhor Arquitetura para Factory Service:**

# âœ… **FastAPI + Celery + Workers + QR sob demanda**

### **Componentes:**

1. **API REST (FastAPI):**
   - Recebe requests sÃ­ncronos
   - INSERT batch + enfileira job
   - Retorna imediatamente (<50ms)

2. **Worker Pool (Celery):**
   - 10-20 workers background
   - Processa batches em paralelo
   - ThreadPool + ProcessPool interno

3. **QR Codes sob demanda:**
   - Gera dinamicamente via `/qrcode/{token}.svg`
   - Cache em CloudFront (CDN)
   - Economiza S3 storage

4. **Bulk Operations:**
   - PostgreSQL COPY (5x mais rÃ¡pido)
   - S3 upload paralelo (6x mais rÃ¡pido)
   - Merkle tree otimizado

### **Performance:**

```
Throughput: 4-12 batches/minuto
Capacidade: 1.7M produtos/dia âœ…
LatÃªncia API: <50ms âœ…
Custo: $185/mÃªs âœ…
Escalabilidade: Horizontal (adicionar workers)
```

### **Por que Python/FastAPI?**

1. âœ… **Celery maduro** - worker pool robusto
2. âœ… **Async/await nativo** - I/O paralelo
3. âœ… **ThreadPool + ProcessPool** - paralelismo
4. âœ… **asyncpg** - PostgreSQL performÃ¡tico
5. âœ… **Ecosystem maduro** - PIL, qrcode, boto3
6. âœ… **Dev velocity** - iteraÃ§Ã£o rÃ¡pida

---

## ðŸ”¥ **Go seria melhor?**

### **AnÃ¡lise Go vs Python para Factory Service:**

**Go:**
```
+ ConcorrÃªncia nativa (goroutines)
+ Performance bruta superior
+ Menor memory footprint
- Workers menos maduros (machinery, asynq)
- QR Code libs menos maduras
- Bulk DB operations mais complexas
- Dev velocity menor
```

**Python:**
```
+ Celery MUITO maduro (10+ anos)
+ Workers robustos e testados
+ PIL/Pillow para imagens (maduro)
+ asyncpg + COPY (bulk ops)
+ Dev velocity alto
- Performance bruta menor (mas suficiente)
- Memory footprint maior (mas OK)
```

**Veredito:**  
Para **1M/dia (66 RPS)**, Python Ã© **mais que suficiente** e **mais produtivo**.

**Go seria melhor SE:**
- 100M+/dia (6,600 RPS)
- LatÃªncia API crÃ­tica (<10ms)
- Worker pool precisa de 1000+ workers

**Para escala atual:** âœ… **Python/FastAPI Ã© ideal**

---

## ðŸ“ˆ **Roadmap de Escalabilidade**

### **Fase 1: 1M produtos/dia (atual)**

```
Stack: FastAPI + Celery + 10 workers
Custo: $185/mÃªs
Performance: âœ… Sobra capacidade
```

### **Fase 2: 10M produtos/dia (10x)**

```
Stack: FastAPI + Celery + 30 workers
Custo: $380/mÃªs
Performance: âœ… EscalÃ¡vel horizontal
OtimizaÃ§Ã£o: Adicionar workers
```

### **Fase 3: 100M produtos/dia (100x)**

```
Stack: FastAPI + Celery + 100 workers
Custo: $1,200/mÃªs
Performance: âš ï¸ Apertado
OtimizaÃ§Ã£o: Considerar Go rewrite
```

**EstratÃ©gia:** Python atÃ© 10-50M/dia, Go apÃ³s isso (SE necessÃ¡rio).

---

## ðŸŽ¯ **TL;DR**

**Pergunta:** Qual melhor arquitetura para Factory Service com 1M ancoragens/dia?

**Resposta:** âœ… **FastAPI + Celery Workers + QR sob demanda**

**Componentes:**

1. **API REST:** FastAPI (Python) - resposta <50ms
2. **Workers:** Celery (10-20 workers) - processamento paralelo
3. **QR Codes:** Sob demanda via CDN - economia de storage
4. **DB:** PostgreSQL COPY bulk - 5x mais rÃ¡pido
5. **S3:** Upload paralelo (100 threads) - 6x mais rÃ¡pido

**Performance:**

- Throughput: **1.7M produtos/dia** âœ…
- LatÃªncia API: **<50ms** âœ…
- Custo: **$185/mÃªs** âœ…
- Escalabilidade: Horizontal (adicionar workers)

**Por que nÃ£o Go?**

- Python aguenta 1M/dia com sobra
- Celery Ã© mais maduro que workers Go
- Ecosystem Python mais rico (PIL, boto3)
- 3x mais rÃ¡pido para desenvolver
- Go seria over-engineering para essa escala

**Migrar para Go apenas SE:**

- Crescer para 100M+/dia
- LatÃªncia API virar crÃ­tica (<10ms)
- Dados mostrarem necessidade real

**Filosofia:** "Use the right tool for the scale you HAVE, not the scale you HOPE to have."